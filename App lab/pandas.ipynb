{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "series1=pd.Series({'A':100,'B':200,'C':300,'D':400,'E':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    100\n",
       "B    200\n",
       "C    300\n",
       "D    400\n",
       "E    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2=series1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    200\n",
       "B    400\n",
       "C    600\n",
       "D    800\n",
       "E    200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(series2['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    10000\n",
      "B    20000\n",
      "dtype: int64\n",
      "A     10000.0\n",
      "B     40000.0\n",
      "C         NaN\n",
      "D    120000.0\n",
      "E         NaN\n",
      "G         NaN\n",
      "H         NaN\n",
      "dtype: float64\n",
      "A    1000\n",
      "B    2000\n",
      "D    3000\n",
      "G    4000\n",
      "dtype: int64\n",
      "H    1000\n",
      "G    4000\n",
      "D    3000\n",
      "B    2000\n",
      "A    1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1=pd.Series({'A':100,'B':200,'C':300,'D':400,'E':100})\n",
    "s2=pd.Series({'A':100,'B':200,'D':300,'G':400,'H':100})\n",
    "print(s1[:2]*100)\n",
    "print(s1*s2)\n",
    "print(s2[ : -1]*10) # except last \n",
    "print(s2[ :: -1]*10) # except from reverse order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     99\n",
      "B    200\n",
      "C      0\n",
      "D      0\n",
      "E    100\n",
      "dtype: int64\n",
      "A     99\n",
      "B    200\n",
      "C      0\n",
      "D      0\n",
      "E    100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1.iloc[0]=99\n",
    "print(s1)\n",
    "s1[2:4]=000\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 and last 3 rows of IPL DataFrame:\n",
      "           Player            Team Category  BidPrice  Runs\n",
      "0   Hardik Pandya  Mumbai Indians  Batsman        13  1000\n",
      "1        KL Rahul    Kings Eleven  Batsman        12  2400\n",
      "3  Jasprit Bumrah  Mumbai Indians   Bowler        10   200\n",
      "4     Virat Kohli             RCB  Batsman        17  3600\n",
      "5    Rohit Sharma  Mumbai Indians  Batsman        15  3700\n",
      "\n",
      "\n",
      "Sum of each column in Weather DataFrame:\n",
      "MaxTemp     242.0\n",
      "MinTemp     176.0\n",
      "RainFall    207.5\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Missing values in each column:\n",
      "    Name   City    Age  Salary\n",
      "0  False  False  False   False\n",
      "1  False   True  False   False\n",
      "2  False  False   True    True\n",
      "3   True  False  False   False\n",
      "4  False  False  False   False\n",
      "\n",
      "\n",
      "Count of missing values in each column:\n",
      "Name      1\n",
      "City      1\n",
      "Age       1\n",
      "Salary    1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Percentage of missing values in each column:\n",
      "Name      20.0\n",
      "City      20.0\n",
      "Age       20.0\n",
      "Salary    20.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Solution 6 - IPL DataFrame\n",
    "ipl_data = {\n",
    "    'Player': ['Hardik Pandya', 'KL Rahul', 'Andre Russel', 'Jasprit Bumrah', 'Virat Kohli', 'Rohit Sharma'],\n",
    "    'Team': ['Mumbai Indians', 'Kings Eleven', 'Kolkata Knight riders', 'Mumbai Indians', 'RCB', 'Mumbai Indians'],\n",
    "    'Category': ['Batsman', 'Batsman', 'Batsman', 'Bowler', 'Batsman', 'Batsman'],\n",
    "    'BidPrice': [13, 12, 7, 10, 17, 15],\n",
    "    'Runs': [1000, 2400, 900, 200, 3600, 3700]\n",
    "}\n",
    "ipl_df = pd.DataFrame(ipl_data)\n",
    "\n",
    "# Get first 2 and last 3 rows\n",
    "print(\"First 2 and last 3 rows of IPL DataFrame:\")\n",
    "result_1=pd.concat([ipl_df.head(2),ipl_df.tail(3)])\n",
    "print(result_1)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Solution 7 - Weather DataFrame\n",
    "weather_data = {\n",
    "    'MaxTemp': [45, 34, 48, 32, 44, 39],\n",
    "    'MinTemp': [30, 24, 34, 22, 29, 37],\n",
    "    'City': ['Delhi', 'Guwahati', 'Chennai', 'Bangluru', 'Mumbai', 'Jaipur'],\n",
    "    'RainFall': [25.6, 41.5, 36.8, 40.2, 38.5, 24.9]\n",
    "}\n",
    "df = pd.DataFrame(weather_data)\n",
    "\n",
    "# Calculate sum of every column\n",
    "print(\"Sum of each column in Weather DataFrame:\")\n",
    "print(df.sum(numeric_only=True)) # important\n",
    "print(\"\\n\")\n",
    "\n",
    "# Solution 8 - Missing Values Analysis\n",
    "data = {\n",
    "    'Name': ['Anna', 'Ben', 'Cathy', np.nan, 'Edward'],\n",
    "    'City': ['New York', np.nan, 'Chicago', 'Los Angeles', 'San Francisco'],\n",
    "    'Age': [25, 30, np.nan, 22, 35],\n",
    "    'Salary': [50000, 60000, np.nan, 52000, 70000]\n",
    "}\n",
    "df_missing = pd.DataFrame(data)\n",
    "\n",
    "# Identify missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df_missing.isnull())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Count missing values in each column\n",
    "print(\"Count of missing values in each column:\")\n",
    "print(df_missing.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"Percentage of missing values in each column:\")\n",
    "# print((df_missing.isnull().sum() / len(df_missing) * 100).round(2))\n",
    "print((df_missing.isnull().sum()/len(df_missing)*100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived                   0.0\n",
      "Pclass                     0.0\n",
      "Name                       0.0\n",
      "Sex                        0.0\n",
      "Age                        0.0\n",
      "Siblings/Spouses Aboard    0.0\n",
      "Parents/Children Aboard    0.0\n",
      "Fare                       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_data=df.isnull().sum()/len(df)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_drop=missing_data[missing_data>0.4].index\n",
    "df.drop(columns=column_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_1292\\1797164797.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(),inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                             Mr. Owen Harris Braund   \n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
      "2         1       3                              Miss. Laina Heikkinen   \n",
      "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
      "4         0       3                            Mr. William Henry Allen   \n",
      "\n",
      "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
      "0    male  22.0                        1                        0   7.2500  \n",
      "1  female  38.0                        1                        0  71.2833  \n",
      "2  female  26.0                        0                        0   7.9250  \n",
      "3  female  35.0                        1                        0  53.1000  \n",
      "4    male  35.0                        0                        0   8.0500  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Embarked'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Embarked'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian(),inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m],inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Embarked'"
     ]
    }
   ],
   "source": [
    "df['Age'].fillna(df['Age'].median(),inplace=True)\n",
    "print(df.head())\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cabin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# forward fill andre we enter a last enter value\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'"
     ]
    }
   ],
   "source": [
    "# forward fill andre we enter a last enter value\n",
    "df['Cabin'].fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cabin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHas_Cabin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\shara\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'"
     ]
    }
   ],
   "source": [
    "df['Has_Cabin'] = df['Cabin'].notnull().astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Item', 'Measure_1', 'Measure_2', 'Measure_3', 'Measure_4'], dtype='object')\n",
      "LLLLLLLLLLLLLLLLLLL\n",
      "Original DataFrame:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "2  2021-10-03     NaN        NaN        NaN        NaN        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        NaN       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39   1.745967\n",
      "\n",
      "Dropped Rows:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "\n",
      "Dropped Columns:\n",
      "          Date\n",
      "0  2021-10-01\n",
      "1  2021-10-02\n",
      "2  2021-10-03\n",
      "3  2021-10-04\n",
      "4  2021-10-05\n",
      "5  2021-10-06\n",
      "6  2021-10-07\n",
      "7  2021-10-08\n",
      "8  2021-10-09\n",
      "9  2021-10-10\n",
      "\n",
      "Dropped Only Missing Rows:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "2  2021-10-03     NaN        NaN        NaN        NaN        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        NaN       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39   1.745967\n",
      "\n",
      "Dropped Only Missing Columns:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "2  2021-10-03     NaN        NaN        NaN        NaN        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        NaN       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39   1.745967\n",
      "\n",
      "Threshold Dropped Rows:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        NaN       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39   1.745967\n",
      "\n",
      "Threshold Dropped Columns:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16\n",
      "2  2021-10-03     NaN        NaN        NaN        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60\n",
      "7  2021-10-08  1014.0        NaN       0.45       0.00\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39\n",
      "\n",
      "Filled Previous:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "2  2021-10-03  1014.0        1.0       0.84       0.16        NaN\n",
      "3  2021-10-04  1014.0        3.0       0.84       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        8.0       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10  1014.0        1.0       0.01       0.39   1.745967\n",
      "\n",
      "Filled Previous with Limit:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79        NaN\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16        NaN\n",
      "2  2021-10-03  1014.0        1.0       0.84       0.16        NaN\n",
      "3  2021-10-04  1014.0        3.0        NaN       0.26        NaN\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91        NaN\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64        NaN\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60        NaN\n",
      "7  2021-10-08  1014.0        8.0       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10  1014.0        1.0       0.01       0.39   1.745967\n",
      "\n",
      "Filled Forward:\n",
      "          Date    Item  Measure_1  Measure_2  Measure_3  Measure_4\n",
      "0  2021-10-01  1014.0        8.0       0.53       0.79  -1.000761\n",
      "1  2021-10-02  1014.0        1.0       0.84       0.16  -1.000761\n",
      "2  2021-10-03  1014.0        3.0       0.08       0.26  -1.000761\n",
      "3  2021-10-04  1014.0        3.0       0.08       0.26  -1.000761\n",
      "4  2021-10-05  1014.0        5.0       0.08       0.91  -1.000761\n",
      "5  2021-10-06  1014.0        6.0       0.94       0.64  -1.000761\n",
      "6  2021-10-07  1014.0        8.0       0.17       0.60  -1.000761\n",
      "7  2021-10-08  1014.0        1.0       0.45       0.00  -1.000761\n",
      "8  2021-10-09  1014.0        1.0       0.44       0.72  -1.871924\n",
      "9  2021-10-10     NaN        NaN       0.01       0.39   1.745967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_25228\\2865097467.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_previous = df.fillna(method=\"ffill\")\n",
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_25228\\2865097467.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_previous_limit = df.fillna(method=\"ffill\", limit=1)\n",
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_25228\\2865097467.py:40: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_forward = df.fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating the DataFrame\n",
    "data = {\n",
    "    \"Date\": [\"2021-10-01\", \"2021-10-02\", \"2021-10-03\", \"2021-10-04\", \"2021-10-05\", \"2021-10-06\", \n",
    "             \"2021-10-07\", \"2021-10-08\", \"2021-10-09\", \"2021-10-10\"],\n",
    "    \"Item\": [1014.0, 1014.0, np.nan, 1014.0, 1014.0, 1014.0, 1014.0, 1014.0, 1014.0, np.nan],\n",
    "    \"Measure_1\": [8.0, 1.0, np.nan, 3.0, 5.0, 6.0, 8.0, np.nan, 1.0, np.nan],\n",
    "    \"Measure_2\": [0.53, 0.84, np.nan, np.nan, 0.08, 0.94, 0.17, 0.45, 0.44, 0.01],\n",
    "    \"Measure_3\": [0.79, 0.16, np.nan, 0.26, 0.91, 0.64, 0.60, 0.00, 0.72, 0.39],\n",
    "    \"Measure_4\": [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, -1.000761, -1.871924, 1.745967],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Drop rows that have a missing value\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# 2. Drop columns that have at least one missing value\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "# 3. Drop rows or columns that only have missing values\n",
    "df_dropped_only_missing_rows = df.dropna(how=\"all\")\n",
    "df_dropped_only_missing_columns = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "print(df.columns)\n",
    "print('LLLLLLLLLLLLLLLLLLL')\n",
    "# 4. Drop rows or columns based on a threshold value (3 or more NaN)\n",
    "df_threshold_rows = df.dropna(thresh=len(df.columns) - 3)\n",
    "df_threshold_columns = df.dropna(axis=1, thresh=len(df) - 3)\n",
    "\n",
    "# 5. Replace NaN with the previous value\n",
    "df_filled_previous = df.fillna(method=\"ffill\")\n",
    "\n",
    "# 6. Replace NaN with the previous value with limit=1\n",
    "df_filled_previous_limit = df.fillna(method=\"ffill\", limit=1)\n",
    "\n",
    "# 7. Replace NaN with the forward value\n",
    "df_filled_forward = df.fillna(method=\"bfill\")\n",
    "\n",
    "# Displaying results\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDropped Rows:\\n\", df_dropped_rows)\n",
    "print(\"\\nDropped Columns:\\n\", df_dropped_columns)\n",
    "print(\"\\nDropped Only Missing Rows:\\n\", df_dropped_only_missing_rows)\n",
    "print(\"\\nDropped Only Missing Columns:\\n\", df_dropped_only_missing_columns)\n",
    "print(\"\\nThreshold Dropped Rows:\\n\", df_threshold_rows)\n",
    "print(\"\\nThreshold Dropped Columns:\\n\", df_threshold_columns)\n",
    "print(\"\\nFilled Previous:\\n\", df_filled_previous)\n",
    "print(\"\\nFilled Previous with Limit:\\n\", df_filled_previous_limit)\n",
    "print(\"\\nFilled Forward:\\n\", df_filled_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dictionaries\n",
    "sales = {'Tony': 103, 'Sally': 202, 'Randy': 380, 'Ellen': 101, 'Fred': 82}\n",
    "region = {'Tony': 'West', 'Sally': 'South', 'Carl': 'West', 'Archie': 'North', 'Randy': 'East', \n",
    "          'Ellen': 'South', 'Fred': np.nan, 'Mo': 'East', 'HanWei': np.nan}\n",
    "\n",
    "# a) Create DataFrames from the dictionaries\n",
    "sales_df = pd.DataFrame.from_dict(sales, orient='index', columns=['sales'])\n",
    "region_df = pd.DataFrame.from_dict(region, orient='index', columns=['region'])\n",
    "\n",
    "# Merge both DataFrames\n",
    "df = pd.merge(region_df, sales_df, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# b) Get the combined output\n",
    "print(df)\n",
    "\n",
    "# c) Filter rows where the index exists in the sales dictionary\n",
    "filtered_df = df[df.index.isin(sales.keys())]\n",
    "print(filtered_df)\n",
    "\n",
    "# d) Group by \"region\" and calculate the sum of \"sales\"\n",
    "grouped_df = df.groupby('region', dropna=True)['sales'].sum().reset_index()\n",
    "print(grouped_df)\n",
    "\n",
    "# e) Add a new column \"sales_region\" with the sum of sales for each region\n",
    "df['sales_region'] = df['region'].map(df.groupby('region')['sales'].sum())\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
